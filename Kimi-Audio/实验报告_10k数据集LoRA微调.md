# Kimi-Audio 10kæ•°æ®é›† LoRA å¾®è°ƒå®éªŒæŠ¥å‘Š

## å®éªŒä¿¡æ¯

- **å®éªŒæ—¥æœŸ**: 2025å¹´11æœˆ14æ—¥
- **å®éªŒç›®æ ‡**: ä½¿ç”¨10kæ•°æ®é›†å¯¹Kimi-Audio-7Bæ¨¡å‹è¿›è¡ŒLoRAå¾®è°ƒï¼Œæå‡ä¸­æ–‡è¯­éŸ³è¯†åˆ«æ€§èƒ½
- **å®éªŒç±»å‹**: å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆLoRA - Low-Rank Adaptationï¼‰

---

## 1. å®éªŒç¯å¢ƒ

### 1.1 ç¡¬ä»¶ç¯å¢ƒ
- **GPUæ•°é‡**: 8å¼ GPUï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
- **è®­ç»ƒæ–¹å¼**: å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒï¼ˆä½¿ç”¨torchrunï¼‰
- **CUDAè®¾å¤‡**: è‡ªåŠ¨æ£€æµ‹å¯ç”¨GPU

### 1.2 è½¯ä»¶ç¯å¢ƒ
- **åŸºç¡€æ¨¡å‹**: `moonshotai/Kimi-Audio-7B`
- **æ¡†æ¶**: PyTorch + HuggingFace Transformers + PEFT
- **è®­ç»ƒä¼˜åŒ–**: DeepSpeed Zero3ï¼ˆè‡ªåŠ¨å¯ç”¨ï¼‰
- **ç²¾åº¦**: BFloat16

### 1.3 é¡¹ç›®è·¯å¾„
```
/mnt/workspace/hyq/code/come_in/asr/xjz-assignment/kimi-audio/Kimi-Audio
```

---

## 2. æ•°æ®é›†å‡†å¤‡

### 2.1 æ•°æ®æ¥æº
- **åŸå§‹æ•°æ®**: `split_lingyin_audio_info.csv`ï¼ˆå¤§è§„æ¨¡CSVæ–‡ä»¶ï¼‰
- **æ•°æ®æå–**: ä»åŸå§‹CSVä¸­æå–å‰10,000è¡Œ
- **æå–åæ–‡ä»¶**: `split_lingyin_audio_10k.csv`

### 2.2 æ•°æ®é¢„å¤„ç†æµç¨‹

#### æ­¥éª¤1: CSVè½¬JSONLæ ¼å¼
- **è„šæœ¬**: `finetune_codes/demo_data/audio_understanding/prepare_data.py`
- **åŠŸèƒ½**: 
  - è¯»å–CSVæ–‡ä»¶ï¼ˆåŒ…å«`id`å’Œ`no_point_text`å­—æ®µï¼‰
  - æ„å»ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆ`{audio_dir}/{id}.wav`ï¼‰
  - è½¬æ¢ä¸ºJSONLæ ¼å¼ï¼ŒåŒ…å«ï¼š
    - `task_type`: "understanding"
    - `conversation`: åŒ…å«ç”¨æˆ·æŒ‡ä»¤ã€éŸ³é¢‘è·¯å¾„ã€æ ‡å‡†ç­”æ¡ˆ
- **è¾“å‡º**: `data_10k.jsonl`ï¼ˆ10,001è¡Œï¼ŒåŒ…å«è¡¨å¤´ï¼‰

#### æ­¥éª¤2: æå–è¯­ä¹‰éŸ³é¢‘Token
- **è„šæœ¬**: `finetune_codes/extract_semantic_codes.py`
- **åŠŸèƒ½**: 
  - åŠ è½½Kimi-Audioæ¨¡å‹
  - å¯¹æ¯ä¸ªéŸ³é¢‘æ–‡ä»¶è¿›è¡Œtokenization
  - å°†`audio_tokens`æ·»åŠ åˆ°JSONLæ•°æ®ä¸­
- **è¾“å‡º**: `data_10k_with_semantic_codes.jsonl`ï¼ˆ10,001è¡Œï¼‰
- **é‡è¦æ€§**: è®­ç»ƒæ—¶éœ€è¦é¢„tokenizeçš„éŸ³é¢‘æ•°æ®ï¼Œé¿å…æ¯ä¸ªepoché‡å¤è®¡ç®—

### 2.3 æ•°æ®é›†ç»Ÿè®¡
- **è®­ç»ƒæ ·æœ¬æ•°**: 10,000æ¡
- **æ•°æ®æ ¼å¼**: JSONLï¼Œæ¯è¡ŒåŒ…å«ï¼š
  ```json
  {
    "task_type": "understanding",
    "conversation": [
      {"role": "user", "message_type": "text", "content": "è¯·å°†è¯­éŸ³å†…å®¹è½¬å½•ä¸ºæ–‡å­—ã€‚"},
      {"role": "user", "message_type": "audio", "content": "/path/to/audio.wav", "audio_tokens": [...]},
      {"role": "assistant", "message_type": "text", "content": "æ ‡å‡†ç­”æ¡ˆæ–‡æœ¬"}
    ]
  }
  ```
- **ä»»åŠ¡ç±»å‹**: è¯­éŸ³è¯†åˆ«ï¼ˆASR - Automatic Speech Recognitionï¼‰

---

## 3. å®éªŒé…ç½®

### 3.1 LoRAå‚æ•°é…ç½®

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `lora_rank` | 8 | LoRAçš„ç§©ï¼Œæ§åˆ¶é€‚é…å™¨çš„å®¹é‡ |
| `lora_alpha` | 16 | LoRAçš„ç¼©æ”¾å› å­ï¼Œé€šå¸¸ä¸ºrankçš„2å€ |
| `lora_dropout` | 0.05 | LoRAå±‚çš„dropoutç‡ |
| `lora_target` | "all" | åº”ç”¨åˆ°æ‰€æœ‰çº¿æ€§å±‚ |

**å¯è®­ç»ƒå‚æ•°å æ¯”**: çº¦0.25%ï¼ˆç›¸æ¯”å…¨é‡å¾®è°ƒå¤§å¹…å‡å°‘ï¼‰

### 3.2 è®­ç»ƒè¶…å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `num_train_epochs` | 5 | è®­ç»ƒè½®æ•° |
| `per_device_train_batch_size` | 1 | æ¯ä¸ªè®¾å¤‡çš„æ‰¹æ¬¡å¤§å° |
| `gradient_accumulation_steps` | 8 | æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆæœ‰æ•ˆbatch size = 1 Ã— 8 Ã— 8 = 64ï¼‰ |
| `learning_rate` | 5e-5 | å­¦ä¹ ç‡ï¼ˆç›¸æ¯”åˆå§‹1e-4é™ä½ï¼‰ |
| `model_max_length` | 8192 | æ¨¡å‹æœ€å¤§åºåˆ—é•¿åº¦ |
| `eval_ratio` | 0.05 | éªŒè¯é›†æ¯”ä¾‹ï¼ˆ500ä¸ªæ ·æœ¬ï¼‰ |
| `bf16` | True | ä½¿ç”¨BFloat16ç²¾åº¦ |
| `logging_steps` | 50 | æ¯50æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿— |
| `save_steps` | 1000 | æ¯1000æ­¥ä¿å­˜ä¸€æ¬¡checkpoint |
| `save_total_limit` | 5 | æœ€å¤šä¿å­˜5ä¸ªcheckpoint |

### 3.3 è®­ç»ƒé…ç½®è„šæœ¬
- **è„šæœ¬è·¯å¾„**: `finetune_codes/finetune_lora.sh`
- **ç‰¹ç‚¹**: 
  - è‡ªåŠ¨æ£€æµ‹GPUæ•°é‡
  - å•GPUä½¿ç”¨`python`ï¼Œå¤šGPUä½¿ç”¨`torchrun`
  - æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ

---

## 4. è®­ç»ƒè¿‡ç¨‹

### 4.1 è®­ç»ƒå¯åŠ¨
```bash
cd /mnt/workspace/hyq/code/come_in/asr/xjz-assignment/kimi-audio/Kimi-Audio
bash finetune_codes/finetune_lora.sh
```

### 4.2 è®­ç»ƒç»Ÿè®¡
- **æ€»è®­ç»ƒæ­¥æ•°**: 745æ­¥ï¼ˆ5ä¸ªepochï¼‰
- **è®¡ç®—æ–¹å¼**: 
  - æ€»æ ·æœ¬æ•°: 10,000
  - æœ‰æ•ˆbatch size: 1 Ã— 8 (GPUs) Ã— 8 (gradient_accumulation) = 64
  - æ¯epochæ­¥æ•°: 10,000 / 64 â‰ˆ 157æ­¥
  - æ€»æ­¥æ•°: 157 Ã— 5 â‰ˆ 745æ­¥

### 4.3 é‡åˆ°çš„é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### é—®é¢˜1: æ•°æ®ç±»å‹ä¸åŒ¹é…
**é”™è¯¯ä¿¡æ¯**:
```
RuntimeError: expected mat1 and mat2 to have the same dtype, but got: float != c10::BFloat16
```

**åŸå› **: åœ¨å¤šGPUè®­ç»ƒæ—¶ï¼ŒDeepSpeed Zero3å¯¹æ•°æ®ç±»å‹æ£€æŸ¥æ›´ä¸¥æ ¼ã€‚`expanded_whisper`æ˜¯float32ï¼Œè€Œæ¨¡å‹æƒé‡æ˜¯BFloat16ã€‚

**è§£å†³æ–¹æ¡ˆ**: 
åœ¨`finetune_codes/modeling_kimia.py`ä¸­æ·»åŠ ç±»å‹è½¬æ¢ï¼š
```python
expanded_whisper = expanded_whisper.to(dtype=audio_emb.dtype)
```

#### é—®é¢˜2: å¼ é‡ç»´åº¦ä¸åŒ¹é…
**é”™è¯¯ä¿¡æ¯**:
```
RuntimeError: The expanded size of the tensor (402) must match the existing size (375) at non-singleton dimension 0
```

**åŸå› **: ä¸åŒéŸ³é¢‘çš„`whisper_input_feature`é•¿åº¦ä¸åŒï¼Œå¯¼è‡´èµ‹å€¼æ—¶ç»´åº¦ä¸åŒ¹é…ã€‚

**è§£å†³æ–¹æ¡ˆ**: 
æ·»åŠ è¾¹ç•Œæ£€æŸ¥å’Œé•¿åº¦åŒ¹é…é€»è¾‘ï¼š
```python
actual_end_idx = min(end_idx, expanded_whisper.shape[0])
actual_feat_len = actual_end_idx - (start_idx + 1)
available_feat_len = min(actual_feat_len, whisper_input_feature_i.shape[0])
if actual_feat_len > 0 and start_idx + 1 < expanded_whisper.shape[0]:
    target_end = min(start_idx + 1 + available_feat_len, expanded_whisper.shape[0])
    expanded_whisper[start_idx + 1 : target_end, :] = (
        whisper_input_feature_i[:available_feat_len, :]
    )
```

### 4.4 è®­ç»ƒè¾“å‡º
- **è¾“å‡ºç›®å½•**: `output/lora_finetuned/`
- **ä¿å­˜å†…å®¹**:
  - LoRAé€‚é…å™¨æƒé‡: `adapter_model.safetensors`
  - LoRAé…ç½®: `adapter_config.json`
  - è®­ç»ƒæ£€æŸ¥ç‚¹: `checkpoint-*`ï¼ˆæ¯1000æ­¥ä¿å­˜ä¸€æ¬¡ï¼‰
  - è®­ç»ƒçŠ¶æ€: `trainer_state.json`

---

## 5. æ¨¡å‹åˆå¹¶ä¸å¯¼å‡º

### 5.1 LoRAé€‚é…å™¨åˆå¹¶
- **è„šæœ¬**: `merge_lora_adapter.py`
- **åŠŸèƒ½**: å°†è®­ç»ƒå¥½çš„LoRAé€‚é…å™¨åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹ä¸­
- **è¾“å…¥**:
  - åŸºç¡€æ¨¡å‹: `output/pretrained_hf`
  - LoRAé€‚é…å™¨: `output/lora_finetuned`
- **è¾“å‡º**: `output/lora_merged_for_inference/`
  - åˆå¹¶åçš„å®Œæ•´æ¨¡å‹ï¼ˆ8ä¸ªåˆ†ç‰‡ï¼‰
  - Whisperç¼–ç å™¨: `whisper-large-v3/`
  - æ¨¡å‹é…ç½®å’Œä»£ç 

### 5.2 åˆå¹¶ç»“æœéªŒè¯
- âœ… æ¨¡å‹æ–‡ä»¶å®Œæ•´ï¼ˆ8ä¸ªsafetensorsåˆ†ç‰‡ï¼‰
- âœ… é…ç½®æ–‡ä»¶å­˜åœ¨
- âœ… Whisperæ¨¡å‹å·²ä¿å­˜
- âš ï¸ Text tokenizerä»é»˜è®¤è·¯å¾„åŠ è½½ï¼ˆä¸å½±å“åŠŸèƒ½ï¼‰

---

## 6. æ¨¡å‹æµ‹è¯•ä¸è¯„ä¼°

### 6.1 æµ‹è¯•æ•°æ®é›†
- **æµ‹è¯•æ–‡ä»¶**: `finetune_codes/demo_data/audio_understanding/split_lingyin_audio_answer.csv`
- **æµ‹è¯•æ ·æœ¬æ•°**: 10ä¸ªéŸ³é¢‘æ ·æœ¬
- **æµ‹è¯•è„šæœ¬**: `finetune_codes/demo_data/audio_understanding/test_model.py`

### 6.2 æµ‹è¯•é…ç½®
- **æ¨¡å‹è·¯å¾„**: `output/lora_merged_for_inference`
- **é‡‡æ ·å‚æ•°**:
  - `audio_temperature`: 0.8
  - `text_temperature`: 0.3ï¼ˆä»0.0è°ƒæ•´ï¼‰
  - `text_top_k`: 5
  - `audio_top_k`: 10

### 6.3 æµ‹è¯•ç»“æœ

#### æ•´ä½“æ€§èƒ½
- **æ€»æµ‹è¯•æ•°**: 10
- **å®Œå…¨åŒ¹é…**: 1
- **åŒ¹é…ç‡**: 10.00%

#### è¯¦ç»†ç»“æœåˆ†æ

| æ ·æœ¬ID | åŒ¹é…çŠ¶æ€ | ä¸»è¦å·®å¼‚ |
|--------|---------|---------|
| 1 | âœ— | "èµ„æ–™è¡¨"â†’"èµ„äº§è´Ÿå€ºè¡¨"ï¼Œ"ä¾›åº”ä»·å€¼å˜åŠ¨"â†’"ä¾›åº”å‹åŠ›å˜åŠ¨" |
| 2 | âœ— | ç¼ºå°‘"é‚£"å’Œ"æ²¡ï¼Ÿ" |
| 3 | âœ— | ç¼ºå°‘"è¿™"ï¼Œ"æœ‰ç†è§£"â†’"æœ‰äº›æœ‰ä»·å€¼" |
| 4 | âœ— | äººåè¯†åˆ«é”™è¯¯ï¼ˆ"å¼ å‹‡"â†’"é˜¿å‹‡"ï¼Œ"å´è€€é£"â†’"é‚£ä¸ªè°"ï¼‰ |
| 5 | âœ— | ç¼ºå°‘"å¯¹"å’Œ"OK" |
| 6 | âœ— | "5Gçš„åŸºæœ¬"â†’"æœºæ„äºº"ï¼Œ"æ¯ä¸ª"â†’"ä½ ä»¬" |
| 7 | âœ— | "LPL"â†’"LP"ï¼ˆç¼©å†™è¯†åˆ«é—®é¢˜ï¼‰ |
| 8 | âœ“ | **å®Œå…¨åŒ¹é…** |
| 9 | âœ— | "7000ä¸‡"â†’"ä¸ƒåƒä¸‡"ï¼ˆæ•°å­—æ ¼å¼ï¼‰ï¼Œ"å°±å®šäº†"â†’"å°±å¦å¤–" |
| 10 | âœ— | "æ°¸è¿œ"â†’"å› ä¸º"ï¼Œ"æ¥çœ‹"â†’"æ¥ç”Ÿäº§" |

#### é”™è¯¯æ¨¡å¼åˆ†æ
1. **äººåè¯†åˆ«**: äººåè¯†åˆ«å‡†ç¡®ç‡è¾ƒä½ï¼ˆæ ·æœ¬4ï¼‰
2. **æ•°å­—æ ¼å¼**: é˜¿æ‹‰ä¼¯æ•°å­—ä¸ä¸­æ–‡æ•°å­—æ··ç”¨ï¼ˆæ ·æœ¬9ï¼‰
3. **ä¸“ä¸šæœ¯è¯­**: éƒ¨åˆ†ä¸“ä¸šæœ¯è¯­è¯†åˆ«ä¸å‡†ç¡®ï¼ˆæ ·æœ¬1ã€6ï¼‰
4. **è¯­æ°”è¯**: è¯­æ°”è¯ï¼ˆ"é‚£"ã€"å¯¹"ã€"OK"ï¼‰æœ‰æ—¶è¢«çœç•¥
5. **åŒéŸ³å­—**: å­˜åœ¨åŒéŸ³å­—æ··æ·†ï¼ˆæ ·æœ¬10ï¼š"æ°¸è¿œ"â†’"å› ä¸º"ï¼‰

### 6.4 æˆåŠŸæ¡ˆä¾‹
**æ ·æœ¬8**å®Œå…¨åŒ¹é…ï¼Œè¯´æ˜æ¨¡å‹å…·å¤‡è‰¯å¥½çš„è¯†åˆ«èƒ½åŠ›ï¼š
- æ ‡å‡†ç­”æ¡ˆ: "æˆ‘ä»Šå¤©åœ¨äºŒçº§å¸‚åœºçš„ä¸Šé¢çš„ä¼°å€¼ï¼Œ8æœˆ15å·æˆ‘çœ‹åˆ°æ•°æ®æ˜¯1.3äº¿ç¾å…ƒã€‚"
- æ¨¡å‹è¾“å‡º: "æˆ‘ä»Šå¤©åœ¨äºŒçº§å¸‚åœºçš„ä¸Šé¢çš„ä¼°å€¼ï¼Œ8æœˆ15å·æˆ‘çœ‹åˆ°æ•°æ®æ˜¯1.3äº¿ç¾å…ƒã€‚"

---

## 7. ç»“æœåˆ†æä¸è®¨è®º

### 7.1 æ€§èƒ½åˆ†æ
- **åŒ¹é…ç‡è¾ƒä½çš„åŸå› **:
  1. **è®­ç»ƒè½®æ•°ä¸è¶³**: ä»…å®Œæˆ1ä¸ªepochï¼ˆè®¡åˆ’5ä¸ªepochï¼‰ï¼Œæ¨¡å‹å°šæœªå……åˆ†å­¦ä¹ 
  2. **æ•°æ®é›†ç‰¹ç‚¹**: æµ‹è¯•æ•°æ®åŒ…å«ä¸“ä¸šæœ¯è¯­ã€äººåã€æ•°å­—ç­‰å¤æ‚å†…å®¹
  3. **æ¨¡å‹å®¹é‡**: LoRA rank=8å¯èƒ½å¯¹å¤æ‚ä»»åŠ¡å®¹é‡ä¸è¶³
  4. **æ¸©åº¦å‚æ•°**: text_temperature=0.3å¼•å…¥äº†éšæœºæ€§ï¼Œå¯èƒ½å½±å“å‡†ç¡®æ€§

### 7.2 æ¨¡å‹è¡¨ç°
- **ä¼˜ç‚¹**:
  - èƒ½å¤Ÿè¯†åˆ«å¤§éƒ¨åˆ†å†…å®¹ï¼Œè¯­ä¹‰æ¥è¿‘æ ‡å‡†ç­”æ¡ˆ
  - æ•°å­—è¯†åˆ«ç›¸å¯¹å‡†ç¡®ï¼ˆå¦‚"7000ä¸‡"ã€"1.3äº¿ç¾å…ƒ"ï¼‰
  - èƒ½å¤Ÿå¤„ç†è¾ƒé•¿çš„å¥å­
- **ä¸è¶³**:
  - äººåè¯†åˆ«å‡†ç¡®ç‡ä½
  - ä¸“ä¸šæœ¯è¯­è¯†åˆ«ä¸ç¨³å®š
  - è¯­æ°”è¯å’Œæ ‡ç‚¹ç¬¦å·å¤„ç†ä¸å®Œå–„

### 7.3 ä¸é¢„æœŸå¯¹æ¯”
- **é¢„æœŸ**: é€šè¿‡10kæ•°æ®é›†å¾®è°ƒï¼ŒæœŸæœ›åŒ¹é…ç‡è¾¾åˆ°50%ä»¥ä¸Š
- **å®é™…**: 10%ï¼ˆä»…1ä¸ªepochï¼‰
- **å·®è·åŸå› **: è®­ç»ƒæœªå®Œæˆï¼Œæ¨¡å‹å°šæœªæ”¶æ•›

---

## 8. æŠ€æœ¯è¦ç‚¹æ€»ç»“

### 8.1 Tokenizationçš„ä½œç”¨
- **æ–‡æœ¬Tokenization**: å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—IDåºåˆ—
- **éŸ³é¢‘Tokenization**: å°†éŸ³é¢‘æ³¢å½¢å‹ç¼©ä¸ºè¯­ä¹‰tokenåºåˆ—
- **è®­ç»ƒæ—¶**: éœ€è¦é¢„tokenizeï¼ˆæ•ˆç‡è€ƒè™‘ï¼‰
- **æ¨ç†æ—¶**: å¯ä»¥å®æ—¶tokenizeï¼ˆçµæ´»æ€§ï¼‰

### 8.2 LoRAå¾®è°ƒä¼˜åŠ¿
- **å‚æ•°æ•ˆç‡**: ä»…è®­ç»ƒ0.25%çš„å‚æ•°
- **å†…å­˜å‹å¥½**: ç›¸æ¯”å…¨é‡å¾®è°ƒå¤§å¹…é™ä½æ˜¾å­˜éœ€æ±‚
- **å¿«é€Ÿè®­ç»ƒ**: è®­ç»ƒé€Ÿåº¦å¿«ï¼Œé€‚åˆå¿«é€Ÿè¿­ä»£
- **æ˜“äºéƒ¨ç½²**: å¯ä»¥åˆå¹¶ä¸ºå®Œæ•´æ¨¡å‹æˆ–å•ç‹¬ä½¿ç”¨é€‚é…å™¨

### 8.3 å¤šGPUè®­ç»ƒ
- **DeepSpeed Zero3**: è‡ªåŠ¨å¯ç”¨ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨
- **åˆ†å¸ƒå¼è®­ç»ƒ**: ä½¿ç”¨torchrunå®ç°å¤šGPUå¹¶è¡Œ
- **æ•°æ®ç±»å‹ä¸€è‡´æ€§**: åœ¨å¤šGPUè®­ç»ƒä¸­éœ€è¦ç‰¹åˆ«æ³¨æ„æ•°æ®ç±»å‹åŒ¹é…

---

## 9. æ”¹è¿›å»ºè®®

### 9.1 è®­ç»ƒç›¸å…³
1. **å®Œæˆå…¨éƒ¨è®­ç»ƒ**: ç»§ç»­è®­ç»ƒå‰©ä½™4ä¸ªepochï¼Œè§‚å¯Ÿæ€§èƒ½æå‡
2. **è°ƒæ•´å­¦ä¹ ç‡**: å¯ä»¥å°è¯•æ›´å°çš„å­¦ä¹ ç‡ï¼ˆå¦‚2e-5ï¼‰è¿›è¡Œç²¾ç»†è°ƒä¼˜
3. **å¢åŠ LoRA rank**: å°è¯•rank=16æˆ–32ï¼Œå¢åŠ æ¨¡å‹å®¹é‡
4. **æ•°æ®å¢å¼º**: å¯¹éŸ³é¢‘è¿›è¡Œé€Ÿåº¦ã€éŸ³é‡ç­‰å¢å¼º

### 9.2 è¯„ä¼°ç›¸å…³
1. **æ‰©å¤§æµ‹è¯•é›†**: ä½¿ç”¨æ›´å¤šæµ‹è¯•æ ·æœ¬ï¼ˆå¦‚100-1000ä¸ªï¼‰
2. **ä½¿ç”¨è¯„ä¼°æŒ‡æ ‡**: é™¤äº†å®Œå…¨åŒ¹é…ï¼Œä½¿ç”¨WERï¼ˆè¯é”™è¯¯ç‡ï¼‰ã€CERï¼ˆå­—é”™è¯¯ç‡ï¼‰ç­‰æŒ‡æ ‡
3. **æ¸©åº¦å‚æ•°è°ƒä¼˜**: å°è¯•ä¸åŒçš„text_temperatureå€¼ï¼ˆ0.0, 0.1, 0.2, 0.3ï¼‰
4. **å¤šæ¬¡æµ‹è¯•**: ç”±äºéšæœºæ€§ï¼Œè¿›è¡Œå¤šæ¬¡æµ‹è¯•å–å¹³å‡

### 9.3 æ•°æ®å¤„ç†
1. **æ•°æ®æ¸…æ´—**: æ£€æŸ¥å¹¶æ¸…ç†è®­ç»ƒæ•°æ®ä¸­çš„é”™è¯¯æ ‡æ³¨
2. **æ•°æ®å¹³è¡¡**: ç¡®ä¿ä¸åŒåœºæ™¯ã€ä¸åŒè¯´è¯äººçš„æ•°æ®å¹³è¡¡
3. **æ•°æ®é‡æ‰©å±•**: è€ƒè™‘æ‰©å±•åˆ°50kæˆ–100kæ•°æ®é›†

---

## 10. å®éªŒç»“è®º

### 10.1 ä¸»è¦æˆæœ
1. âœ… æˆåŠŸå®Œæˆ10kæ•°æ®é›†çš„LoRAå¾®è°ƒæµç¨‹
2. âœ… è§£å†³äº†å¤šGPUè®­ç»ƒä¸­çš„æ•°æ®ç±»å‹å’Œç»´åº¦åŒ¹é…é—®é¢˜
3. âœ… æˆåŠŸåˆå¹¶LoRAé€‚é…å™¨å¹¶å¯¼å‡ºæ¨ç†æ¨¡å‹
4. âœ… å»ºç«‹äº†å®Œæ•´çš„è®­ç»ƒ-æµ‹è¯•æµç¨‹

### 10.2 å½“å‰çŠ¶æ€
- **è®­ç»ƒçŠ¶æ€**: å®Œæˆ1/5 epochï¼ˆ745æ­¥ä¸­çš„çº¦149æ­¥ï¼‰
- **æ¨¡å‹çŠ¶æ€**: å·²ä¿å­˜checkpointï¼Œå¯ç»§ç»­è®­ç»ƒ
- **æµ‹è¯•ç»“æœ**: 10%åŒ¹é…ç‡ï¼ˆä»…1ä¸ªepochï¼Œæœªå……åˆ†è®­ç»ƒï¼‰

### 10.3 ä¸‹ä¸€æ­¥è®¡åˆ’
1. ç»§ç»­è®­ç»ƒå‰©ä½™4ä¸ªepoch
2. ä½¿ç”¨æ›´å¤§æµ‹è¯•é›†è¿›è¡Œè¯„ä¼°
3. å°è¯•ä¸åŒçš„è¶…å‚æ•°ç»„åˆ
4. åˆ†æè®­ç»ƒlossæ›²çº¿ï¼Œåˆ¤æ–­æ˜¯å¦è¿‡æ‹Ÿåˆ

---

## 11. é™„å½•

### 11.1 å…³é”®æ–‡ä»¶è·¯å¾„
- è®­ç»ƒè„šæœ¬: `finetune_codes/finetune_lora.sh`
- è®­ç»ƒä»£ç : `finetune.py`
- æ•°æ®å‡†å¤‡: `finetune_codes/demo_data/audio_understanding/prepare_data.py`
- Tokenæå–: `finetune_codes/extract_semantic_codes.py`
- æ¨¡å‹åˆå¹¶: `merge_lora_adapter.py`
- æµ‹è¯•è„šæœ¬: `finetune_codes/demo_data/audio_understanding/test_model.py`

### 11.2 è¾“å‡ºç›®å½•ç»“æ„
```
output/
â”œâ”€â”€ pretrained_hf/              # åŸºç¡€æ¨¡å‹
â”œâ”€â”€ lora_finetuned/             # LoRAé€‚é…å™¨
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â””â”€â”€ checkpoint-*/
â””â”€â”€ lora_merged_for_inference/  # åˆå¹¶åçš„æ¨ç†æ¨¡å‹
    â”œâ”€â”€ model-*.safetensors
    â”œâ”€â”€ config.json
    â””â”€â”€ whisper-large-v3/
```

### 11.3 å‚è€ƒèµ„æ–™
- [PEFTæ–‡æ¡£](https://huggingface.co/docs/peft)
- [LoRAè®ºæ–‡](https://arxiv.org/abs/2106.09685)
- [DeepSpeedæ–‡æ¡£](https://www.deepspeed.ai/)

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2025å¹´11æœˆ14æ—¥  
**å®éªŒçŠ¶æ€**: ğŸŸ¡ è¿›è¡Œä¸­ï¼ˆ1/5 epochå®Œæˆï¼‰  
**æŠ¥å‘Šä½œè€…**: AI Assistant

